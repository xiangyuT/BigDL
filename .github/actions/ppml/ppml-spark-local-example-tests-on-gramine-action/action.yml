name: 'PPML-spark-Local-Example-Tests-on-Gramine'
description: 'PPML-spark-Local-Example-Tests-on-Gramine'
inputs:
  image:
    description: 'image'
    required: true
    default: '10.239.45.10/arda/intelanalytics/bigdl-ppml-trusted-big-data-ml-python-gramine'
  image-tag:
    description: 'image tag'
    required: true
    default: 'latest'
runs:
  using: "composite"
  steps:
    - uses: actions/checkout@v3
    - name: Set Variable
      shell: bash
      env:
        DEFAULT_SGX_MEM_SIZE: 32G
        DEFAULT_IMAGE: ${{ inputs.image }}:${{ inputs.image-tag }}
      run: |
        echo "HDFS_ADDRESS=172.168.0.206:9000" >> $GITHUB_ENV
        echo "CONTAINER_NAME=spark-examples-test-gramine" >> $GITHUB_ENV
        echo "SGX_MEM_SIZE=${{ env.DEFAULT_SGX_MEM_SIZE }}" >> $GITHUB_ENV
        echo "IMAGE=${{ env.DEFAULT_IMAGE }}" >> $GITHUB_ENV

    - name: Start Container
      shell: bash
      run: |
        set -x
        docker pull ${IMAGE}
        docker rm -f ${CONTAINER_NAME}
        docker run -id --privileged --net=host --name ${CONTAINER_NAME} \
        --cpuset-cpus=$CPUSET \
        --oom-kill-disable \
        --device=/dev/sgx/enclave \
        --device=/dev/sgx/provision \
        -v ~/glorysdj/kuberconfig:/root/.kube/config \
        -v /var/run/aesmd/aesm.socket:/var/run/aesmd/aesm.socket \
        -v $DATA_PATH:/ppml/trusted-big-data-ml/work/data \
        -v $KEYS_PATH:/ppml/trusted-big-data-ml/work/keys \
        -e LOCAL_IP=$LOCAL_IP \
        -e HDFS_ADDRESS=$HDFS_ADDRESS \
        -e SGX_MEM_SIZE=$SGX_MEM_SIZE \
        -e RUNTIME_K8S_SERVICE_ACCOUNT=spark \
        -e RUNTIME_K8S_SPARK_IMAGE=$IMAGE \
        -e RUNTIME_DRIVER_HOST=$LOCAL_IP \
        -e RUNTIME_DRIVER_PORT=54321 \
        -e RUNTIME_EXECUTOR_INSTANCES=1 \
        -e RUNTIME_EXECUTOR_CORES=4 \
        -e RUNTIME_EXECUTOR_MEMORY=80g \
        -e RUNTIME_TOTAL_EXECUTOR_CORES=4 \
        -e RUNTIME_DRIVER_CORES=4 \
        -e RUNTIME_DRIVER_MEMORY=10g \
        $IMAGE bash
    - name: Spark Examples Test
      shell: bash
      run: |
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/init.sh"
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-python-helloword-on-sgx.sh"
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-python-numpy-on-sgx.sh"
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-python-fgboost-server-on-sgx.sh"
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-python-fl-server-on-sgx.sh"
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-spark-pi-on-local-sgx.sh"
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-pyspark-pi-on-local-sgx.sh"
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-pyspark-simpleexamples-on-local-sgx.sh"
        /opt/hadoop-3.2.0/bin/hadoop fs -rm -r -f hdfs://$HDFS_ADDRESS/spark-warehous
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-spark-sqlexamples-on-local-sgx.sh"
        /opt/hadoop-3.2.0/bin/hadoop fs -rm -r -f hdfs://$HDFS_ADDRESS/spark-warehous
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-pyspark-sqlexamples-on-local-sgx.sh"
        docker exec -i $CONTAINER_NAME bash -c "/ppml/trusted-big-data-ml/work/scripts/start-pyspark-sqlApi-on-local-sgx.sh"
